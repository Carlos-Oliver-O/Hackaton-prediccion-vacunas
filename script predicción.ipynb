{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTACIÓN LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA DE CSV Y PROCESAMIENTO DATATIME DE FECHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"DF Precisión, Temperaturas y OF.csv\")\n",
    "df[\"Fecha/hora inicio\"] = pd.to_datetime(df[\"Fecha/hora inicio\"])\n",
    "df[\"Fecha/hora fin\"] = pd.to_datetime(df[\"Fecha/hora fin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA DE CSV Y LIMPIEZA DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv(\"OF 123456 v03.csv\", encoding=\"Latin1\")\n",
    "dd[\"Cantidad entregada\"] = dd[\"Cantidad entregada\"].astype(str).str.replace(\",\", \".\")\n",
    "dd['Cantidad entregada'] = dd['Cantidad entregada'].str.replace(\"0\", \"\")\n",
    "dd[\"Lote\"]= dd[\"Lote\"].str.replace(\"/\",\"\")\n",
    "df[\"Cantidad entregada\"] = dd[\"Cantidad entregada\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREACIÓN DE NUEVAS VARIABLES SACANDO EL PROMEDIO Y MULTIPLICANDO VARIABLES PARA VER EL IMPACTO DE LA COMBINACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Indice_condiciones_almacen'] = (df['Temperatura almacén principal (inicio)'] + df['Temperatura almacén producción (inicio)']) / 2\n",
    "df['Interaccion_temp_hum'] = df['Temperatura biorreactores (inicio)'] * df['Humedad biorreactores (inicio)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCATENAR MEDIAS CON EL CSV QUE TENEMOS TODAS LAS VARIABLES TRANSFORMADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias = pd.read_csv(\"resultado_media_temperaturas (1).csv\")\n",
    "df_test = pd.read_csv(\"DF test con todo.csv\")\n",
    "df_test = pd.concat([df_test, medias], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCATENADO DE NUEVAS VARIABLES Y DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_train = pd.read_csv(\"resultado_media_biorreactores_centrifugas.csv\")\n",
    "df = pd.concat([df, medias_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECCIÓN DE VARIABLES PARA EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['LOTE',\n",
    " 'Volumen de inóculo utilizado',\n",
    " 'Viabilidad final cultivo',\n",
    " 'Centrifugación 1 turbidez',\n",
    " 'Centrifugación 2 turbidez',\n",
    " 'Humedad almacén producción (inicio)',\n",
    " 'Humedad almacén producción (fin)',\n",
    " 'Humedad biorreactores (inicio)',\n",
    " 'Temperatura biorreactores (fin)',\n",
    " 'Temperatura centrifugas (inicio)',\n",
    " 'Cantidad entregada',\n",
    " 'Indice_condiciones_almacen',\n",
    " 'Interaccion_temp_hum',\n",
    " 'Humedad almacén principal (media)',\n",
    " 'Temperatura biorreactores (media)',\n",
    " 'Producto 1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['LOTE',\n",
    " 'Volumen de inóculo utilizado',\n",
    " 'Viabilidad final cultivo',\n",
    " 'Centrifugación 1 turbidez',\n",
    " 'Centrifugación 2 turbidez',\n",
    " 'Humedad almacén producción (inicio)',\n",
    " 'Humedad almacén producción (fin)',\n",
    " 'Humedad biorreactores (inicio)',\n",
    " 'Temperatura biorreactores (fin)',\n",
    " 'Temperatura centrifugas (inicio)',\n",
    " 'Cantidad entregada',\n",
    " 'Indice_condiciones_almacen',\n",
    " 'Interaccion_temp_hum',\n",
    " 'Humedad almacén principal (media)',\n",
    " 'Temperatura biorreactores (media)',\n",
    " 'Producto 1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SACAR MEDIANAS DE LOS OUT LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Centrifugación 1 turbidez'].quantile(0.25)\n",
    "Q3 = df['Centrifugación 1 turbidez'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['Centrifugación 1 turbidez'] = df['Centrifugación 1 turbidez'].apply(\n",
    "    lambda x: df['Centrifugación 1 turbidez'].median() if x < lower_bound or x > upper_bound else x\n",
    ")\n",
    "\n",
    "Q1 = df['Centrifugación 2 turbidez'].quantile(0.25)\n",
    "Q3 = df['Centrifugación 2 turbidez'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['Centrifugación 2 turbidez'] = df['Centrifugación 2 turbidez'].apply(\n",
    "    lambda x: df['Centrifugación 2 turbidez'].median() if x < lower_bound or x > upper_bound else x\n",
    ")\n",
    "\n",
    "Q1 = df['Temperatura biorreactores (fin)'].quantile(0.25)\n",
    "Q3 = df['Temperatura biorreactores (fin)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['Temperatura biorreactores (fin)'] = df['Temperatura biorreactores (fin)'].apply(\n",
    "    lambda x: df['Temperatura biorreactores (fin)'].median() if x < lower_bound or x > upper_bound else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIÓN DE ENTRENAMIENTO DE MODELO CON PARAMETROS, ESCALADO DE LOS DATOS Y PARTICIÓN DE TEST TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(df, target_column):\n",
    "    # Definir X e y\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "    # Escalar los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convertir a DataFrame para mantener los nombres de columnas\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "    # Definir el modelo XGBRegressor con los parámetros especificados\n",
    "    model = XGBRegressor(\n",
    "        max_depth=2,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=550,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        alpha=0.1,\n",
    "        reg_lambda=1,\n",
    "        gamma=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    print(\"Training XGBRegressor...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluar en conjunto de prueba\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f\"XGBRegressor - Test R²: {r2}, MSE: {mse}, RMSE: {rmse}\")\n",
    "\n",
    "    # Convertir los resultados a DataFrame\n",
    "    results_df = pd.DataFrame([{\n",
    "        'Model': 'XGBRegressor',\n",
    "        'Train R² (CV)': model.score(X_train_scaled, y_train),\n",
    "        'Test MSE': mse,\n",
    "        'Test RMSE': rmse,\n",
    "        'Test R²': r2\n",
    "    }])\n",
    "\n",
    "    return model, scaler, results_df\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_model(trained_model, scaler, predict_df):\n",
    "    \"\"\"\n",
    "    Genera predicciones utilizando un modelo entrenado y un escalador.\n",
    "\n",
    "    Args:\n",
    "        trained_model: Modelo entrenado.\n",
    "        scaler: Escalador ajustado.\n",
    "        predict_df (pd.DataFrame): DataFrame con las características para predecir.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Predicciones del modelo.\n",
    "    \"\"\"\n",
    "    # Escalar datos\n",
    "    X_scaled = scaler.transform(predict_df)\n",
    "    predictions = trained_model.predict(X_scaled)\n",
    "    return pd.Series(predictions, name='Predicción')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMAR A LA FUNCIÓN Y DARLE LOS PARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBRegressor...\n",
      "XGBRegressor - Test R²: 0.42246916100928533, MSE: 42117.63026818626, RMSE: 205.22580312471982\n"
     ]
    }
   ],
   "source": [
    "best_model, scaler, results_df = train_and_evaluate_models(df, target_column='Producto 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=['Producto 1'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HACER PREDICCIONES DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1454.314941\n",
      "1     1617.307861\n",
      "2     1482.116821\n",
      "3     1374.013550\n",
      "4     1250.369629\n",
      "5     1372.709839\n",
      "6     1505.699341\n",
      "7     1468.254028\n",
      "8     1259.354126\n",
      "9      965.291992\n",
      "10    1409.793823\n",
      "11    1460.327148\n",
      "12    1252.439087\n",
      "13    1446.718994\n",
      "14    1503.704468\n",
      "15    1555.890747\n",
      "16    1374.065186\n",
      "17    1250.210083\n",
      "18    1291.697998\n",
      "19    1235.219849\n",
      "20    1292.248047\n",
      "21    1308.480957\n",
      "22    1320.460938\n",
      "23    1367.539795\n",
      "24    1109.661499\n",
      "25    1228.758301\n",
      "26    1325.146484\n",
      "27    1367.583008\n",
      "28    1373.256348\n",
      "29    1369.824219\n",
      "30    1578.615723\n",
      "31    1428.766968\n",
      "32    1261.742188\n",
      "33    1265.631592\n",
      "34    1424.238770\n",
      "35    1414.708008\n",
      "36    1416.445801\n",
      "37    1471.947754\n",
      "38    1210.987915\n",
      "39    1132.222168\n",
      "40    1465.848389\n",
      "41    1249.028442\n",
      "42    1179.102295\n",
      "43    1460.562256\n",
      "44    1497.570923\n",
      "45    1464.879150\n",
      "46    1550.379395\n",
      "47    1429.218384\n",
      "48    1241.954102\n",
      "49    1251.831787\n",
      "50    1523.206787\n",
      "51    1475.573364\n",
      "52    1326.424805\n",
      "53    1460.611572\n",
      "54    1474.858521\n",
      "Name: Predicción, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_with_model(best_model, scaler, df_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lote = df_test[\"LOTE\"]\n",
    "df_ent =predictions.to_frame()\n",
    "df_concat = pd.concat([df_lote,df_ent], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv(\"CVC DATA_UH2024.txt\",index=False, header=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
